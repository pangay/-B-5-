{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于飞桨实现乒乓球时序动作定位大赛-第五名方案\n",
    "\n",
    "### 赛题介绍\n",
    "\n",
    "在众多大规模视频分析情景中，从冗长未经修剪的视频中定位并识别短时间内发生的人体动作成为一个备受关注的课题。当前针对人体动作检测的解决方案在大规模视频集上难以奏效，高效地处理大规模视频数据仍然是计算机视觉领域一个充满挑战的任务。其核心问题可以分为两部分，一是动作识别算法的复杂度仍旧较高，二是缺少能够产生更少视频提案数量的方法（更加关注短时动作本身的提案）。\n",
    "\n",
    "这里所指的视频动作提案是指一些包含特定动作的候选视频片段。为了能够适应大规模视频分析任务，时序动作提案应该尽可能满足下面两个需求：\n",
    "（1）更高的处理效率，例如可以设计出使时序视频片段编码和打分更高效的机制；\n",
    "（2）更强的判别性能，例如可以准确定位动作发生的时间区间。\n",
    "\n",
    "本次比赛旨在激发更多的开发者和研究人员关注并参与有关视频动作定位的研究，创建性能更出色的动作定位模型。\n",
    "\n",
    "### 方法介绍\n",
    "本项目使用PaddleVideo的[BMN](https://github.com/PaddlePaddle/PaddleVideo/blob/develop/docs/zh-CN/model_zoo/localization/bmn.md)模型\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e10bf1fdde9f4c61ae2d5c4ecfa3d7b2c16ed59ee7a247f1b86c84ad59e71e72)\n",
    "\n",
    "BMN模型是百度自研，2019年ActivityNet夺冠方案，为视频动作定位问题中proposal的生成提供高效的解决方案，在PaddlePaddle上首次开源。此模型引入边界匹配(Boundary-Matching, BM)机制来评估proposal的置信度，按照proposal开始边界的位置及其长度将所有可能存在的proposal组合成一个二维的BM置信度图，图中每个点的数值代表其所对应的proposal的置信度分数。网络由三个模块组成，基础模块作为主干网络处理输入的特征序列，TEM模块预测每一个时序位置属于动作开始、动作结束的概率，PEM模块生成BM置信度图。\n",
    "\n",
    "### 改进\n",
    "\n",
    "主要改进的地方在于：\n",
    "\n",
    "1.先通过分割验证集 选取训练中效果最好的epoch范围；再使用全部数据进行训练 提高训练效果。\n",
    "\n",
    "2.分割数据的时候使用FootballAciton的划分方法，最大的保留用于训练的数据数量。\n",
    "\n",
    "3.在预测的时候 存在一些片段 处在两个划分之间的间隔处，这会降低预测的质量。所以我在想是否可以将这部分被分割在间隔处的片段利用起来，虽然有了一些想法，但是迫于时间，未能进行验证，期待下次比赛可以验证一下是否有效。\n",
    "\n",
    "### 数据集介绍\n",
    "\n",
    "本次比赛的数据集包含了19-21赛季兵乓球国际比赛（世界杯、世锦赛、亚锦赛，奥运会）和国内比赛（全运会，乒超联赛）中标准单机位高清转播画面的特征信息，共包含912条视频特征文件，每个视频时长在0～6分钟不等，特征维度为2048，以pkl格式保存。我们对特征数据中面朝镜头的运动员的回合内挥拍动作进行了标注，单个动作时常在0～2秒不等，训练数据为729条标注视频，A测数据为91条视频，B测数据为92条视频，训练数据标签以json格式给出。\n",
    "\n",
    "### 数据集预处理\n",
    "\n",
    "本方案采用PaddleVideo中的BMN模型。BMN模型是百度自研，2019年ActivityNet夺冠方案，为视频动作定位问题中proposal的生成提供高效的解决方案，在PaddlePaddle上首次开源。此模型引入边界匹配(Boundary-Matching, BM)机制来评估proposal的置信度，按照proposal开始边界的位置及其长度将所有可能存在的proposal组合成一个二维的BM置信度图，图中每个点的数值代表其所对应的proposal的置信度分数。网络由三个模块组成，基础模块作为主干网络处理输入的特征序列，TEM模块预测每一个时序位置属于动作开始、动作结束的概率，PEM模块生成BM置信度图。\n",
    "\n",
    "本赛题中的数据包含912条ppTSM抽取的视频特征，特征保存为pkl格式，文件名对应视频名称，读取pkl之后以(num_of_frames, 2048)向量形式代表单个视频特征。其中num_of_frames是不固定的，同时数量也比较大，所以pkl的文件并不能直接用于训练。同时由于乒乓球每个动作时间非常短，为了可以让模型更好的识别动作，所以这里将数据进行分割。\n",
    "\n",
    "\n",
    "1. 首先解压数据集\n",
    "执行以下命令解压数据集，解压之后将压缩包删除，保证项目空间小于100G。否则项目会被终止。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T14:45:42.172102Z",
     "iopub.status.busy": "2022-02-23T14:45:42.171563Z",
     "iopub.status.idle": "2022-02-23T14:55:43.193869Z",
     "shell.execute_reply": "2022-02-23T14:55:43.192795Z",
     "shell.execute_reply.started": "2022-02-23T14:45:42.172061Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/data/\n",
    "!tar xf data122998/Features_competition_train.tar.gz\n",
    "!tar xf data123004/Features_competition_test_A.tar.gz\n",
    "!cp data122998/label_cls14_train.json .\n",
    "!rm -rf data12*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T14:55:43.263425Z",
     "iopub.status.busy": "2022-02-23T14:55:43.263114Z",
     "iopub.status.idle": "2022-02-23T14:55:43.631125Z",
     "shell.execute_reply": "2022-02-23T14:55:43.630249Z",
     "shell.execute_reply.started": "2022-02-23T14:55:43.263382Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 解压好数据之后，首先对label标注文件进行分割。本项目在Baseline的基础上参照[FootballAciton](https://github.com/PaddlePaddle/PaddleVideo/blob/application/FootballAction/datasets/script/get_instance_for_bmn.py)的划分方法，进一步优化训练数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T15:08:00.300024Z",
     "iopub.status.busy": "2022-02-23T15:08:00.298897Z",
     "iopub.status.idle": "2022-02-23T15:08:00.303944Z",
     "shell.execute_reply": "2022-02-23T15:08:00.302868Z",
     "shell.execute_reply.started": "2022-02-23T15:08:00.299973Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_path = \"/home/aistudio/data/label_cls14_train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T15:08:04.101033Z",
     "iopub.status.busy": "2022-02-23T15:08:04.100456Z",
     "iopub.status.idle": "2022-02-23T15:08:04.237750Z",
     "shell.execute_reply": "2022-02-23T15:08:04.236858Z",
     "shell.execute_reply.started": "2022-02-23T15:08:04.100991Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/aistudio/data/label_cls14_train.json') as f:\n",
    "    data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T15:08:06.582314Z",
     "iopub.status.busy": "2022-02-23T15:08:06.581838Z",
     "iopub.status.idle": "2022-02-23T15:08:06.878506Z",
     "shell.execute_reply": "2022-02-23T15:08:06.877460Z",
     "shell.execute_reply.started": "2022-02-23T15:08:06.582276Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#先按照9:1划分训练 测试集 后将所有数据都作为训练集 \n",
    "l=len(data['gts'])\n",
    "l=int(l*0.1)\n",
    "val = {'gts': data['gts'][0:l], 'fps': 25}\n",
    "jsonString = json.dumps(val, indent=4, ensure_ascii=False)\n",
    "jsonFile = open('/home/aistudio/data/label_cls14_val.json', 'w')\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()\n",
    "\n",
    "train = {'gts': data['gts'][l:], 'fps': 25}\n",
    "jsonString = json.dumps(train, indent=4, ensure_ascii=False)\n",
    "jsonFile = open('/home/aistudio/data/label_cls14_train.json', 'w')\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T15:08:08.793610Z",
     "iopub.status.busy": "2022-02-23T15:08:08.793245Z",
     "iopub.status.idle": "2022-02-23T15:12:02.975573Z",
     "shell.execute_reply": "2022-02-23T15:12:02.974807Z",
     "shell.execute_reply.started": "2022-02-23T15:08:08.793574Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save feature for bmn ...\n",
      "miss number (broken sample): 110\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "get instance for bmn\n",
    "使用winds=4的滑窗，将所有子窗口的长度之和小于winds的进行合并\n",
    "合并后，父窗口代表bmn训练数据，子窗口代表tsn训练数据\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# for table tennis\n",
    "bmn_window = 4\n",
    "dataset = \"/home/aistudio/data\"\n",
    "feat_dir = dataset + '/Features_competition_train'\n",
    "out_dir = dataset + '/Input_for_bmn'\n",
    "label_files = {\n",
    "    'train': 'label_cls14_train.json',\n",
    "    'validation': 'label_cls14_val.json'\n",
    "}\n",
    "\n",
    "global fps\n",
    "\n",
    "\n",
    "def gen_gts_for_bmn(gts_data):\n",
    "    \"\"\"\n",
    "    @param, gts_data, original gts for action detection\n",
    "    @return, gts_bmn, output gts dict for bmn\n",
    "    \"\"\"\n",
    "    fps = gts_data['fps']\n",
    "    gts_bmn = {'fps': fps, 'gts': []}\n",
    "    for sub_item in gts_data['gts']:\n",
    "        url = sub_item['url']\n",
    "\n",
    "        max_length = sub_item['total_frames']\n",
    "\n",
    "        gts_bmn['gts'].append({\n",
    "            'url': url,\n",
    "            'total_frames': max_length,\n",
    "            'root_actions': []\n",
    "        })\n",
    "        sub_actions = sub_item['actions']\n",
    "        # 跳过没有动作的片段\n",
    "        if len(sub_actions) == 0:\n",
    "            continue\n",
    "        # duration > bmn_window， 动作持续时间大于bmn_windows，直接删除\n",
    "        for idx, sub_action in enumerate(sub_actions):\n",
    "            if sub_action['end_id'] - sub_action['start_id'] > bmn_window:\n",
    "                sub_actions.pop(idx)\n",
    "\n",
    "        # 【滑动窗口，把每一个视频里的动作片段提取出来】\n",
    "        root_actions = [sub_actions[0]]\n",
    "        # before_id, 前一动作的最后一帧\n",
    "        # after_id, 后一动作的第一帧\n",
    "        before_id = 0\n",
    "        for idx in range(1, len(sub_actions)):\n",
    "            cur_action = sub_actions[idx]\n",
    "            duration = (cur_action['end_id'] - root_actions[0]['start_id'])\n",
    "            if duration > bmn_window:  # windows只能包住一个动作就包，包不住就包多个\n",
    "                after_id = cur_action['start_id']\n",
    "                gts_bmn['gts'][-1]['root_actions'].append({\n",
    "                    'before_id':\n",
    "                    before_id,\n",
    "                    'after_id':\n",
    "                    after_id,\n",
    "                    'actions':\n",
    "                    root_actions\n",
    "                })\n",
    "                before_id = root_actions[-1]['end_id']  #更新滑窗\n",
    "                root_actions = [cur_action]\n",
    "            else:\n",
    "                root_actions.append(cur_action)\n",
    "            if idx == len(sub_actions) - 1:\n",
    "                after_id = max_length\n",
    "                gts_bmn['gts'][-1]['root_actions'].append({\n",
    "                    'before_id':\n",
    "                    before_id,\n",
    "                    'after_id':\n",
    "                    after_id,\n",
    "                    'actions':\n",
    "                    root_actions\n",
    "                })\n",
    "\n",
    "    return gts_bmn\n",
    "\n",
    "\n",
    "def combile_gts(gts_bmn, gts_process, mode):\n",
    "    \"\"\"\n",
    "    1、bmn_window 范围内只有一个动作，只取一个目标框\n",
    "    2、bmn_window 范围内有多个动作，取三个目标框(第一个动作、最后一个动作、所有动作)\n",
    "    \"\"\"\n",
    "    global fps\n",
    "    fps = gts_process['fps']\n",
    "    duration_second = bmn_window * 1.0\n",
    "    duration_frame = bmn_window * fps\n",
    "    feature_frame = duration_frame\n",
    "    for item in gts_process['gts']:\n",
    "        url = item['url']\n",
    "        basename = os.path.basename(url).split('.')[0]\n",
    "        root_actions = item['root_actions']\n",
    "        # 把每一个视频里的动作片段提取出来\n",
    "        for root_action in root_actions:\n",
    "            segments = []\n",
    "            # all actions\n",
    "            segments.append({\n",
    "                'actions': root_action['actions'],\n",
    "                'before_id': root_action['before_id'],\n",
    "                'after_id': root_action['after_id']\n",
    "            })\n",
    "            if len(root_action['actions']) > 1:  #如果有多个动作，则第一个动作和最后一个动作，额外添加一次\n",
    "                # first action\n",
    "                segments.append({\n",
    "                    'actions': [root_action['actions'][0]],\n",
    "                    'before_id':\n",
    "                    root_action['before_id'],\n",
    "                    'after_id':\n",
    "                    root_action['actions'][1]['start_id']\n",
    "                })\n",
    "                # last action\n",
    "                segments.append({\n",
    "                    'actions': [root_action['actions'][-1]],\n",
    "                    'before_id':\n",
    "                    root_action['actions'][-2]['end_id'],\n",
    "                    'after_id':\n",
    "                    root_action['after_id']\n",
    "                })\n",
    "\n",
    "            # 把动作片段处理成window size大小，以适配BMN输入\n",
    "            for segment in segments:\n",
    "                before_id = segment['before_id']\n",
    "                after_id = segment['after_id']\n",
    "                actions = segment['actions']\n",
    "                # before_id到after_id太长了，从里面取window_size帧，要先确定一个起始点，然后动作都要包住\n",
    "                box0 = max(actions[-1]['end_id'] - bmn_window,\n",
    "                           before_id)  #确定起始点\n",
    "                box1 = min(actions[0]['start_id'],\n",
    "                           after_id - bmn_window)  #确实起始点\n",
    "                if box0 <= box1:  # 一次检查\n",
    "                    if int(box0) - int(box1) == 0:\n",
    "                        cur_start = box0\n",
    "                    else:\n",
    "                        box0 = math.ceil(box0)\n",
    "                        box1 = int(box1)\n",
    "                        cur_start = random.randint(box0, box1)\n",
    "                    cur_end = cur_start + bmn_window\n",
    "                    cur_start = round(cur_start, 2)\n",
    "                    cur_end = round(cur_end, 2)\n",
    "                    name = '{}_{}_{}'.format(basename, cur_start, cur_end)\n",
    "                    annotations = []\n",
    "                    for action in actions:\n",
    "                        label = str(1.0 * action['label_ids'][0])\n",
    "                        label_name = action['label_names'][0]\n",
    "                        seg0 = 1.0 * round((action['start_id'] - cur_start),\n",
    "                                           2)  #存储的是到开始位置(时间: s)的距离\n",
    "                        seg1 = 1.0 * round((action['end_id'] - cur_start), 2)\n",
    "                        annotations.append({\n",
    "                            'segment': [seg0, seg1],\n",
    "                            'label': label,\n",
    "                            'label_name': label_name\n",
    "                        })\n",
    "                    gts_bmn[name] = {\n",
    "                        'duration_second': duration_second,\n",
    "                        'duration_frame': duration_frame,\n",
    "                        'feature_frame': feature_frame,\n",
    "                        'subset': mode,\n",
    "                        'annotations': annotations\n",
    "                    }\n",
    "\n",
    "    return gts_bmn\n",
    "\n",
    "\n",
    "def save_feature_to_numpy(gts_bmn, folder):\n",
    "    global fps\n",
    "    print('save feature for bmn ...')\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    process_gts_bmn = {}\n",
    "    miss = 0\n",
    "    for item, value in gts_bmn.items():\n",
    "        # split to rsplit 针对文件命名修改\n",
    "        basename, start_id, end_id = item.rsplit('_', 2)\n",
    "        if not basename in process_gts_bmn:\n",
    "            process_gts_bmn[basename] = []\n",
    "        process_gts_bmn[basename].append({\n",
    "            'name': item,\n",
    "            'start': float(start_id),\n",
    "            'end': float(end_id)\n",
    "        })\n",
    "    for item, values in process_gts_bmn.items():\n",
    "        feat_path = os.path.join(feat_dir, item + '.pkl')\n",
    "        feature_video = pickle.load(open(feat_path, 'rb'))['image_feature']\n",
    "        for value in values:\n",
    "            save_cut_name = os.path.join(folder, value['name'])\n",
    "            a, b, c = save_cut_name.rsplit('_', 2)\n",
    "            if float(b) > 360:\n",
    "                print(b)\n",
    "            start_frame = round(value['start'] * fps)\n",
    "            end_frame = round(value['end'] * fps)\n",
    "            if end_frame > len(feature_video):\n",
    "                miss += 1\n",
    "                continue\n",
    "            feature_cut = [\n",
    "                feature_video[i] for i in range(start_frame, end_frame)\n",
    "            ]\n",
    "            np_feature_cut = np.array(feature_cut, dtype=np.float32)\n",
    "            np.save(save_cut_name, np_feature_cut)\n",
    "\n",
    "    print('miss number (broken sample):', miss)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    gts_bmn = {}\n",
    "    for item, value in label_files.items():\n",
    "        label_file = os.path.join(dataset, value)\n",
    "        gts_data = json.load(open(label_file, 'rb'))\n",
    "        gts_process = gen_gts_for_bmn(gts_data)\n",
    "        gts_bmn = combile_gts(gts_bmn, gts_process, item)\n",
    "\n",
    "    with open(out_dir + '/label.json', 'w', encoding='utf-8') as f:\n",
    "        data = json.dumps(gts_bmn, indent=4, ensure_ascii=False)\n",
    "        f.write(data)\n",
    "\n",
    "    save_feature_to_numpy(gts_bmn, out_dir + '/feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T15:21:22.479570Z",
     "iopub.status.busy": "2022-02-23T15:21:22.479026Z",
     "iopub.status.idle": "2022-02-23T15:21:26.585431Z",
     "shell.execute_reply": "2022-02-23T15:21:26.584594Z",
     "shell.execute_reply.started": "2022-02-23T15:21:22.479527Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size: 19718\n",
      "(Label) Original size: 19828\n",
      "(Label) Deleted size: 110\n",
      "(Label) Fixed size: 19718\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import copy\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "url = '/home/aistudio/data/Input_for_bmn/feature/'\n",
    "directory = os.fsencode(url)\n",
    "count = 0\n",
    "target_set = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    target_name = filename.split('.npy')[0]\n",
    "    target_set.append(target_name)\n",
    "    count += 1\n",
    "print('Feature size:', len(target_set))\n",
    "\n",
    "with open('/home/aistudio/data/Input_for_bmn/label.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "delet_set = []\n",
    "for key in data.keys():\n",
    "    if not key in target_set:\n",
    "        delet_set.append(key)\n",
    "\n",
    "print('(Label) Original size:', len(data))\n",
    "print('(Label) Deleted size:', len(delet_set))\n",
    "\n",
    "for item in delet_set:\n",
    "    data.pop(item, None)\n",
    "\n",
    "print('(Label) Fixed size:', len(data))\n",
    "\n",
    "jsonString = json.dumps(data, indent=4, ensure_ascii=False)\n",
    "jsonFile = open('/home/aistudio/data/Input_for_bmn/label_fixed.json', 'w')\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行完毕后，在data/Input_for_bmn/目录中生成了新的标注文件label_fixed.json。下面开始分割训练集和测试集的数据。\n",
    "\n",
    "3. 执行以下脚本，分割训练集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T15:21:39.853718Z",
     "iopub.status.busy": "2022-02-23T15:21:39.852549Z",
     "iopub.status.idle": "2022-02-23T15:21:43.926765Z",
     "shell.execute_reply": "2022-02-23T15:21:43.925741Z",
     "shell.execute_reply.started": "2022-02-23T15:21:39.853664Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm /home/aistudio/data/Features_competition_train/*.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行后在data/Features_competition_train/npy目录下生成了训练用的numpy数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T15:24:58.870758Z",
     "iopub.status.busy": "2022-02-23T15:24:58.869716Z",
     "iopub.status.idle": "2022-02-23T15:25:50.122368Z",
     "shell.execute_reply": "2022-02-23T15:25:50.121469Z",
     "shell.execute_reply.started": "2022-02-23T15:24:58.870694Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0223 23:25:08.249946   191 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0223 23:25:08.255378   191 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "import pickle\n",
    "import paddle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "file_list = glob.glob(\"/home/aistudio/data/Features_competition_test_A/*.pkl\")\n",
    "\n",
    "max_frames = 9000\n",
    "\n",
    "npy_path = (\"/home/aistudio/data/Features_competition_test_A/npy/\")\n",
    "if not osp.exists(npy_path):\n",
    "    os.makedirs(npy_path)\n",
    "\n",
    "for f in file_list:\n",
    "    video_feat = pickle.load(open(f, 'rb'))\n",
    "    tensor = paddle.to_tensor(video_feat['image_feature'])\n",
    "    pad_num = 9000 - tensor.shape[0]\n",
    "    pad1d = paddle.nn.Pad1D([0, pad_num])\n",
    "    tensor = paddle.transpose(tensor, [1, 0])\n",
    "    tensor = paddle.unsqueeze(tensor, axis=0)\n",
    "    tensor = pad1d(tensor)\n",
    "    tensor = paddle.squeeze(tensor, axis=0)\n",
    "    tensor = paddle.transpose(tensor, [1, 0])\n",
    "\n",
    "    sps = paddle.split(tensor, num_or_sections=90, axis=0)\n",
    "    for i, s in enumerate(sps):\n",
    "        file_name = osp.join(npy_path, f.split('/')[-1].split('.')[0] + f\"_{i}.npy\")\n",
    "        np.save(file_name, s.detach().numpy())\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "\n",
    "数据集分割好之后，可以开始训练模型，使用以下命令进行模型训练。首先需要安装PaddleVideo的依赖包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T16:35:48.018126Z",
     "iopub.status.busy": "2022-02-23T16:35:48.017557Z",
     "iopub.status.idle": "2022-02-23T16:35:57.712054Z",
     "shell.execute_reply": "2022-02-23T16:35:57.711160Z",
     "shell.execute_reply.started": "2022-02-23T16:35:48.018083Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work\n",
      "正克隆到 'PaddleVideo'...\n",
      "remote: Enumerating objects: 16618, done.\u001b[K\n",
      "remote: Counting objects: 100% (3471/3471), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1414/1414), done.\u001b[K\n",
      "remote: Total 16618 (delta 2196), reused 3147 (delta 1985), pack-reused 13147\u001b[K\n",
      "接收对象中: 100% (16618/16618), 99.00 MiB | 14.60 MiB/s, 完成.\n",
      "处理 delta 中: 100% (11085/11085), 完成.\n",
      "检查连接... 完成。\n"
     ]
    }
   ],
   "source": [
    "# 从Github上下载PaddleVideo代码\n",
    "\n",
    "%cd ~/work/\n",
    "# 从Github上下载PaddleVideo代码\n",
    "!git clone https://github.com/PaddlePaddle/PaddleVideo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd ~/work/PaddleVideo/\n",
    "# 配置PaddleVideo环境\n",
    "!python3.7 -m pip install --upgrade pip\n",
    "!python3.7 -m pip install --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练模型。\n",
    "在/home/aistudio/work/PaddleVideo/applications/TableTennis/configs/bmn_tabletennis.yaml文件中更改文件的路径\n",
    "```\n",
    "DATASET:                                            #DATASET field\n",
    "  batch_size: 16                                 #single card bacth size\n",
    "  test_batch_size: 1\n",
    "  num_workers: 8\n",
    "  train:\n",
    "    format: \"BMNDataset\"\n",
    "    file_path: \"/home/aistudio/data/Input_for_bmn/label_fixed.json\"\n",
    "    subset: \"train\"\n",
    "  valid:\n",
    "    format: \"BMNDataset\"\n",
    "    file_path: \"/home/aistudio/data/Input_for_bmn/label_fixed.json\"\n",
    "    subset: \"validation\"\n",
    "  test:\n",
    "    format: \"BMNDataset\"\n",
    "    test_mode: True\n",
    "    file_path: \"/home/aistudio/work/BMN/Input_for_bmn/label_fixed.json\"\n",
    "    subset: \"validation\"\n",
    "```\n",
    "```\n",
    "PIPELINE:                                           #PIPELINE field\n",
    "  train:                                            #Mandotary, indicate the pipeline to deal with the training data\n",
    "    load_feat:\n",
    "      name: \"LoadFeat\"\n",
    "      feat_path: \"/home/aistudio/data/Input_for_bmn/feature\"\n",
    "    transform:                                      #Mandotary, image transfrom operator\n",
    "      - GetMatchMap:\n",
    "          tscale: 100\n",
    "      - GetVideoLabel:\n",
    "          tscale: 100\n",
    "          dscale: 100\n",
    "\n",
    "  valid:                                            #Mandotary, indicate the pipeline to deal with the training data\n",
    "    load_feat:\n",
    "      name: \"LoadFeat\"\n",
    "      feat_path: \"/home/aistudio/data/Input_for_bmn/feature\"\n",
    "    transform:                                      #Mandotary, image transfrom operator\n",
    "      - GetMatchMap:\n",
    "          tscale: 100\n",
    "      - GetVideoLabel:\n",
    "          tscale: 100\n",
    "          dscale: 100\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T16:48:24.484887Z",
     "iopub.status.busy": "2022-02-23T16:48:24.484297Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/PaddleVideo\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/funnel/modeling.py:30: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "[02/24 00:48:26] DALI is not installed, you can improve performance if use DALI\n",
      "[02/24 00:48:27] \u001b[35mDATASET\u001b[0m : \n",
      "[02/24 00:48:27]     \u001b[35mbatch_size\u001b[0m : \u001b[92m16\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mnum_workers\u001b[0m : \u001b[92m8\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mtest\u001b[0m : \n",
      "[02/24 00:48:27]         \u001b[35mfile_path\u001b[0m : \u001b[92m/home/aistudio/work/BMN/Input_for_bmn/label_fixed.json\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mformat\u001b[0m : \u001b[92mBMNDataset\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35msubset\u001b[0m : \u001b[92mvalidation\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mtest_mode\u001b[0m : \u001b[92mTrue\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mtest_batch_size\u001b[0m : \u001b[92m1\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mtrain\u001b[0m : \n",
      "[02/24 00:48:27]         \u001b[35mfile_path\u001b[0m : \u001b[92m/home/aistudio/data/Input_for_bmn/label_fixed.json\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mformat\u001b[0m : \u001b[92mBMNDataset\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35msubset\u001b[0m : \u001b[92mtrain\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mvalid\u001b[0m : \n",
      "[02/24 00:48:27]         \u001b[35mfile_path\u001b[0m : \u001b[92m/home/aistudio/data/Input_for_bmn/label_fixed.json\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mformat\u001b[0m : \u001b[92mBMNDataset\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35msubset\u001b[0m : \u001b[92mvalidation\u001b[0m\n",
      "[02/24 00:48:27] ------------------------------------------------------------\n",
      "[02/24 00:48:27] \u001b[35mINFERENCE\u001b[0m : \n",
      "[02/24 00:48:27]     \u001b[35mdscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mfeat_dim\u001b[0m : \u001b[92m2048\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mname\u001b[0m : \u001b[92mBMN_Inference_helper\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mresult_path\u001b[0m : \u001b[92mdata/bmn/BMN_INFERENCE_results\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mtscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27] ------------------------------------------------------------\n",
      "[02/24 00:48:27] \u001b[35mMETRIC\u001b[0m : \n",
      "[02/24 00:48:27]     \u001b[35mdscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mfile_path\u001b[0m : \u001b[92m/home/aistudio/work/BMN/Input_for_bmn/label_fixed.json\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mground_truth_filename\u001b[0m : \u001b[92m/home/aistudio/work/BMN/Input_for_bmn/label_gts.json\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mname\u001b[0m : \u001b[92mBMNMetric\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35moutput_path\u001b[0m : \u001b[92mdata/bmn/BMN_Test_output\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mresult_path\u001b[0m : \u001b[92mdata/bmn/BMN_Test_results\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35msubset\u001b[0m : \u001b[92mvalidation\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mtscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27] ------------------------------------------------------------\n",
      "[02/24 00:48:27] \u001b[35mMODEL\u001b[0m : \n",
      "[02/24 00:48:27]     \u001b[35mbackbone\u001b[0m : \n",
      "[02/24 00:48:27]         \u001b[35mdscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mfeat_dim\u001b[0m : \u001b[92m2048\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mname\u001b[0m : \u001b[92mBMN\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mnum_sample\u001b[0m : \u001b[92m32\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mnum_sample_perbin\u001b[0m : \u001b[92m3\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mprop_boundary_ratio\u001b[0m : \u001b[92m0.5\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mtscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mframework\u001b[0m : \u001b[92mBMNLocalizer\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mloss\u001b[0m : \n",
      "[02/24 00:48:27]         \u001b[35mdscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mname\u001b[0m : \u001b[92mBMNLoss\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mtscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27] ------------------------------------------------------------\n",
      "[02/24 00:48:27] \u001b[35mOPTIMIZER\u001b[0m : \n",
      "[02/24 00:48:27]     \u001b[35mlearning_rate\u001b[0m : \n",
      "[02/24 00:48:27]         \u001b[35mboundaries\u001b[0m : \u001b[92m[4200]\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35miter_step\u001b[0m : \u001b[92mTrue\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mname\u001b[0m : \u001b[92mCustomPiecewiseDecay\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mvalues\u001b[0m : \u001b[92m[0.001, 0.0001]\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mname\u001b[0m : \u001b[92mAdam\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mweight_decay\u001b[0m : \n",
      "[02/24 00:48:27]         \u001b[35mname\u001b[0m : \u001b[92mL2\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mvalue\u001b[0m : \u001b[92m0.0001\u001b[0m\n",
      "[02/24 00:48:27] ------------------------------------------------------------\n",
      "[02/24 00:48:27] \u001b[35mPIPELINE\u001b[0m : \n",
      "[02/24 00:48:27]     \u001b[35mtest\u001b[0m : \n",
      "[02/24 00:48:27]         \u001b[35mload_feat\u001b[0m : \n",
      "[02/24 00:48:27]             \u001b[35mfeat_path\u001b[0m : \u001b[92m/home/aistudio/work/BMN/Input_for_bmn/feature\u001b[0m\n",
      "[02/24 00:48:27]             \u001b[35mname\u001b[0m : \u001b[92mLoadFeat\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mtransform\u001b[0m : \n",
      "[02/24 00:48:27]             \u001b[35mGetMatchMap\u001b[0m : \n",
      "[02/24 00:48:27]                 \u001b[35mtscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]             \u001b[35mGetVideoLabel\u001b[0m : \n",
      "[02/24 00:48:27]                 \u001b[35mdscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]                 \u001b[35mtscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mtrain\u001b[0m : \n",
      "[02/24 00:48:27]         \u001b[35mload_feat\u001b[0m : \n",
      "[02/24 00:48:27]             \u001b[35mfeat_path\u001b[0m : \u001b[92m/home/aistudio/data/Input_for_bmn/feature\u001b[0m\n",
      "[02/24 00:48:27]             \u001b[35mname\u001b[0m : \u001b[92mLoadFeat\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mtransform\u001b[0m : \n",
      "[02/24 00:48:27]             \u001b[35mGetMatchMap\u001b[0m : \n",
      "[02/24 00:48:27]                 \u001b[35mtscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]             \u001b[35mGetVideoLabel\u001b[0m : \n",
      "[02/24 00:48:27]                 \u001b[35mdscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]                 \u001b[35mtscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]     \u001b[35mvalid\u001b[0m : \n",
      "[02/24 00:48:27]         \u001b[35mload_feat\u001b[0m : \n",
      "[02/24 00:48:27]             \u001b[35mfeat_path\u001b[0m : \u001b[92m/home/aistudio/data/Input_for_bmn/feature\u001b[0m\n",
      "[02/24 00:48:27]             \u001b[35mname\u001b[0m : \u001b[92mLoadFeat\u001b[0m\n",
      "[02/24 00:48:27]         \u001b[35mtransform\u001b[0m : \n",
      "[02/24 00:48:27]             \u001b[35mGetMatchMap\u001b[0m : \n",
      "[02/24 00:48:27]                 \u001b[35mtscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]             \u001b[35mGetVideoLabel\u001b[0m : \n",
      "[02/24 00:48:27]                 \u001b[35mdscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27]                 \u001b[35mtscale\u001b[0m : \u001b[92m100\u001b[0m\n",
      "[02/24 00:48:27] ------------------------------------------------------------\n",
      "[02/24 00:48:27] \u001b[35mepochs\u001b[0m : \u001b[92m20\u001b[0m\n",
      "[02/24 00:48:27] \u001b[35mlog_level\u001b[0m : \u001b[92mINFO\u001b[0m\n",
      "[02/24 00:48:27] \u001b[35mmodel_name\u001b[0m : \u001b[92mBMN\u001b[0m\n",
      "[02/24 00:48:27] \u001b[35mresume_from\u001b[0m : \u001b[92m\u001b[0m\n",
      "W0224 00:48:27.188020 11538 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0224 00:48:27.192255 11538 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "[02/24 00:48:34] train subset video numbers: 17849\n",
      "[02/24 00:48:34] validation subset video numbers: 1869\n",
      "[02/24 00:48:39] \u001b[35mepoch:[  1/20 ]\u001b[0m \u001b[95mtrain step:0   \u001b[0m \u001b[92mloss: 2.58681 lr: 0.001000\u001b[0m \u001b[92mbatch_cost: 4.95889 sec,\u001b[0m \u001b[92mreader_cost: 2.39032 sec,\u001b[0m ips: 3.22653 instance/sec.\n",
      "[02/24 00:49:04] epoch:[  1/20 ] \u001b[95mtrain step:10  \u001b[0m \u001b[92mloss: 2.40280 lr: 0.001000\u001b[0m \u001b[92mbatch_cost: 2.45601 sec,\u001b[0m \u001b[92mreader_cost: 0.00137 sec,\u001b[0m ips: 6.51463 instance/sec.\n",
      "[02/24 00:49:28] epoch:[  1/20 ] \u001b[95mtrain step:20  \u001b[0m \u001b[92mloss: 2.53095 lr: 0.001000\u001b[0m \u001b[92mbatch_cost: 2.45514 sec,\u001b[0m \u001b[92mreader_cost: 0.00035 sec,\u001b[0m ips: 6.51693 instance/sec.\n",
      "[02/24 00:49:53] epoch:[  1/20 ] \u001b[95mtrain step:30  \u001b[0m \u001b[92mloss: 1.84443 lr: 0.001000\u001b[0m \u001b[92mbatch_cost: 2.45768 sec,\u001b[0m \u001b[92mreader_cost: 0.00184 sec,\u001b[0m ips: 6.51021 instance/sec.\n",
      "[02/24 00:50:17] epoch:[  1/20 ] \u001b[95mtrain step:40  \u001b[0m \u001b[92mloss: 1.62954 lr: 0.001000\u001b[0m \u001b[92mbatch_cost: 2.45935 sec,\u001b[0m \u001b[92mreader_cost: 0.00145 sec,\u001b[0m ips: 6.50579 instance/sec.\n",
      "[02/24 00:50:42] epoch:[  1/20 ] \u001b[95mtrain step:50  \u001b[0m \u001b[92mloss: 1.46614 lr: 0.001000\u001b[0m \u001b[92mbatch_cost: 2.45613 sec,\u001b[0m \u001b[92mreader_cost: 0.00145 sec,\u001b[0m ips: 6.51430 instance/sec.\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/work/PaddleVideo/\n",
    "#!python main.py -c  configs/localization/bmn.yaml\n",
    "!python -B main.py  --validate -c  applications/TableTennis/configs/bmn_tabletennis.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里为了演示训练一个epoch后，停止训练导出模型。实际情况可训练多个epoch，提升模型精度。\n",
    "\n",
    "### 模型导出\n",
    "将训练好的模型导出用于推理预测，执行以下脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T08:10:37.365486Z",
     "iopub.status.busy": "2022-02-21T08:10:37.364567Z",
     "iopub.status.idle": "2022-02-21T08:10:47.261640Z",
     "shell.execute_reply": "2022-02-21T08:10:47.260795Z",
     "shell.execute_reply.started": "2022-02-21T08:10:37.365449Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n",
      "Building model(BMN)...\n",
      "W0221 16:10:39.248404  3357 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0221 16:10:39.252774  3357 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "Loading params from (work/PaddleVideo/output/BMN/BMN_epoch_00006.pdparams)...\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n",
      "model (BMN) has been already saved in (PaddleVideo/inference/BMN).\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/\n",
    "!python work/PaddleVideo/tools/export_model.py -c  work/PaddleVideo/applications/TableTennis/configs/bmn_tabletennis.yaml -p  work/PaddleVideo/output/BMN/BMN_epoch_00007.pdparams -o PaddleVideo/inference/BMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推理预测\n",
    "\n",
    "使用导出的模型进行推理预测，执行以下命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/PaddleVideo/\n",
    "!python tools/predict.py --input_file /home/aistudio/data/Features_competition_test_A/npy \\\n",
    " --config configs/localization/bmn.yaml \\\n",
    " --model_file inference/BMN/BMN.pdmodel \\\n",
    " --params_file inference/BMN/BMN.pdiparams \\\n",
    " --use_gpu=True \\\n",
    " --use_tensorrt=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面程序输出的json文件是分割后的预测结果，还需要将这些文件组合到一起。执行以下脚本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:48:45.605316Z",
     "iopub.status.busy": "2022-02-17T15:48:45.604743Z",
     "iopub.status.idle": "2022-02-17T15:48:45.643099Z",
     "shell.execute_reply": "2022-02-17T15:48:45.642466Z",
     "shell.execute_reply.started": "2022-02-17T15:48:45.605274Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "json_path = \"/home/aistudio/data/Features_competition_test_A/npy/\"\n",
    "json_files = glob.glob(os.path.join(json_path, '*_*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:48:49.093929Z",
     "iopub.status.busy": "2022-02-17T15:48:49.093562Z",
     "iopub.status.idle": "2022-02-17T15:48:49.099031Z",
     "shell.execute_reply": "2022-02-17T15:48:49.098352Z",
     "shell.execute_reply.started": "2022-02-17T15:48:49.093895Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8190"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:48:53.285891Z",
     "iopub.status.busy": "2022-02-17T15:48:53.285531Z",
     "iopub.status.idle": "2022-02-17T15:49:05.857040Z",
     "shell.execute_reply": "2022-02-17T15:49:05.855766Z",
     "shell.execute_reply.started": "2022-02-17T15:48:53.285857Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submit_dic = {\"version\": None,\n",
    "              \"results\": {},\n",
    "              \"external_data\": {}\n",
    "              }\n",
    "results = submit_dic['results']\n",
    "for json_file in json_files:\n",
    "    j = json.load(open(json_file, 'r'))\n",
    "    old_video_name = list(j.keys())[0]\n",
    "    video_name = list(j.keys())[0].split('/')[-1].split('.')[0]\n",
    "    video_name, video_no = video_name.split('_')\n",
    "    start_id = int(video_no) * 4\n",
    "    if len(j[old_video_name]) == 0:\n",
    "        continue\n",
    "    for i, top in enumerate(j[old_video_name]):\n",
    "        if video_name in results.keys():\n",
    "            results[video_name].append({'score': round(top['score'], 2),\n",
    "                                        'segment': [round(top['segment'][0] + start_id, 2), round(top['segment'][1] + start_id, 2)]})\n",
    "        else:\n",
    "            results[video_name] = [{'score':round(top['score'], 2),\n",
    "                                        'segment': [round(top['segment'][0] + start_id, 2), round(top['segment'][1] + start_id, 2)]}]\n",
    "\n",
    "json.dump(submit_dic, open('/home/aistudio/submission.json', 'w', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后会在用户目录生成submission.json文件，压缩后下载提交即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:49:27.313153Z",
     "iopub.status.busy": "2022-02-17T15:49:27.312653Z",
     "iopub.status.idle": "2022-02-17T15:49:28.606535Z",
     "shell.execute_reply": "2022-02-17T15:49:28.605451Z",
     "shell.execute_reply.started": "2022-02-17T15:49:27.313113Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n",
      "  adding: submission.json (deflated 91%)\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/\n",
    "!zip submission.zip submission.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B榜得分 45\n",
    "\n",
    "### 优化思路\n",
    "\n",
    "1. 可以增加训练的epoch数量。\n",
    "2. 可以调整学习率策略，比如warmup和余弦退火等。\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
